{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../apartment/train.csv')\n",
    "test = pd.read_csv('../apartment/test.csv')\n",
    "#train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "catagorical_cols=[]\n",
    "for column in train.columns.values:\n",
    "    if (train[column].dtype=='O'):\n",
    "        catagorical_cols.append(column)\n",
    "\n",
    "\n",
    "for x in catagorical_cols:\n",
    "    train[x]=train[x].fillna('None')\n",
    "    \n",
    "for x in catagorical_cols:\n",
    "    label = preprocessing.LabelEncoder()\n",
    "    train[x] = label.fit_transform(train[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "catagorical_cols1=[]\n",
    "for column in test.columns.values:\n",
    "    if (test[column].dtype=='O'):\n",
    "        catagorical_cols1.append(column)\n",
    "\n",
    "\n",
    "for x in catagorical_cols1:\n",
    "    test[x]=test[x].fillna('None')\n",
    "    \n",
    "for x in catagorical_cols1:\n",
    "    label = preprocessing.LabelEncoder()\n",
    "    test[x] = label.fit_transform(test[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['CarPerArea']=train['GarageArea']/train['GarageCars']\n",
    "train['CarPerArea']=train['CarPerArea'].fillna(train['CarPerArea'].mean())\n",
    "train['basementAnd1stFloorArea'] = train['1stFlrSF']+train['TotalBsmtSF']\n",
    "\n",
    "test['CarPerArea']=test['GarageArea']/test['GarageCars']\n",
    "test['CarPerArea']=test['CarPerArea'].fillna(test['CarPerArea'].mean())\n",
    "test['basementAnd1stFloorArea'] = test['1stFlrSF']+test['TotalBsmtSF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('GarageArea',1)\n",
    "train = train.drop('GarageCars',1)\n",
    "train = train.drop('1stFlrSF',1)\n",
    "train = train.drop('TotalBsmtSF',1)\n",
    "\n",
    "test = test.drop('GarageArea',1)\n",
    "test = test.drop('GarageCars',1)\n",
    "test = test.drop('1stFlrSF',1)\n",
    "test = test.drop('TotalBsmtSF',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model, svm, gaussian_process\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model.stochastic_gradient import SGDRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8 features\n",
    "#cols =['OverallQual','GrLivArea','CarPerArea','basementAnd1stFloorArea','FullBath','YearBuilt','TotRmsAbvGrd','YearRemodAdd']\n",
    "#X = train[cols].values.astype(np.float64)\n",
    "#y = train['SalePrice'].values.astype(np.float64)\n",
    "#X_train,X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = pd.read_csv('../apartment/train.csv')\n",
    "#train1 = train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in train.columns.values:\n",
    "    if(train[x].isnull().sum() >0):\n",
    "        train[x] = train[x].fillna(train[x].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in test.columns.values:\n",
    "    if(test[x].isnull().sum() >0):\n",
    "        test[x] = test[x].fillna(test[x].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = train.columns.difference(['Id','SalePrice'])\n",
    "cols1 = test.columns.difference(['Id','SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[cols].values.astype(np.float64)\n",
    "y = train['SalePrice'].values.astype(np.float64)\n",
    "X_train,X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmaxscaler = preprocessing.MinMaxScaler(copy=True, feature_range=(0, 1)).fit(X)\n",
    "X_train = minmaxscaler.fit_transform(X_train)\n",
    "\n",
    "X_test = minmaxscaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " score:0.138892803634\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "clf = MLPRegressor(solver='lbfgs', activation = 'relu',hidden_layer_sizes=(70,65,60,55,50,45,40,35,30,25,20,15,10,5), max_iter=500, learning_rate='adaptive', batch_size=32)\n",
    "clf.fit(X_train, y_train.ravel())\n",
    "y_pred = clf.predict(X_test)\n",
    "print( \" score:\" + str(np.sqrt(np.mean((np.log(y_pred)-np.log(y_test))*(np.log(y_pred)-np.log(y_test))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense,Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17 layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=77,input_dim=77,kernel_initializer ='normal',activation='relu'))\n",
    "model.add(Dense(units = 70,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units = 65,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units = 60,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units = 55,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units = 50,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units = 45,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units = 40,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units = 35,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units = 30,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units = 25,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units = 20,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units = 15,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units = 10,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units = 5,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units=1,kernel_initializer='normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=77,input_dim=77,kernel_initializer ='normal',activation='relu'))\n",
    "model.add(Dense(units = 75,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units = 70,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units = 65,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units = 53,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units = 60,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units = 55,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units = 53,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units = 50,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units = 45,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units = 40,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units = 35,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units = 33,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units = 30,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units = 25,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units = 20,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units = 15,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units = 10,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units = 5,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units=1,kernel_initializer='normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=77,input_dim=77,kernel_initializer ='normal',activation='relu'))\n",
    "model.add(Dense(units = 130,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units = 190,activation='relu',kernel_initializer = 'normal'))\n",
    "model.add(Dense(units=1,kernel_initializer='normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras import optimizers\n",
    "#sgd = optimizers.SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 969us/step - loss: 22885016505.4560\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 458us/step - loss: 4353648720.8611\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 454us/step - loss: 2746272671.2877\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 443us/step - loss: 1884593311.7965\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 449us/step - loss: 1703650663.2016\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 483us/step - loss: 1496318148.3249\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 1s 506us/step - loss: 1488086982.0939\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 1s 496us/step - loss: 1523875851.0059\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 487us/step - loss: 1342540805.9765\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 1s 529us/step - loss: 1415708598.4658\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 1s 501us/step - loss: 1453858495.9295\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 485us/step - loss: 1445432709.0274\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 1s 516us/step - loss: 1373078970.3464\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 484us/step - loss: 1353661471.8552\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 1s 497us/step - loss: 1360621021.0176\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 1s 490us/step - loss: 1410272883.3699\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 1s 574us/step - loss: 1648322319.0137\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 1s 874us/step - loss: 1362457695.4481\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 1s 556us/step - loss: 1200309547.1712\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 1s 536us/step - loss: 1297675674.6888\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 1s 754us/step - loss: 1360773252.8806\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 1s 524us/step - loss: 1337643880.5470\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 1s 564us/step - loss: 1239864861.4149\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 1s 601us/step - loss: 1261284052.3288\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 1s 593us/step - loss: 1315128255.5421\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 1s 543us/step - loss: 1171775932.8258\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 1s 540us/step - loss: 1269427642.1957\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 1s 762us/step - loss: 1269577313.7339\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 1s 608us/step - loss: 1208041769.42860s - los\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 1s 540us/step - loss: 1242232807.7691\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 1s 532us/step - loss: 1496738975.6595\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 1s 556us/step - loss: 1115759515.7182\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 1s 540us/step - loss: 1113276328.9393\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 1s 537us/step - loss: 1088033110.7221\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 1s 554us/step - loss: 1306290014.9080\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 1s 906us/step - loss: 1159150383.2055\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 1s 598us/step - loss: 1325461713.7466\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 1s 534us/step - loss: 1115239586.4403\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 1s 533us/step - loss: 1288053571.9765\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 1s 779us/step - loss: 1202985109.6986\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 1s 739us/step - loss: 1217885443.4785\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 1s 686us/step - loss: 1249310334.9609\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 1s 757us/step - loss: 1186726214.9628\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 1s 516us/step - loss: 1043007554.7632\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 1s 501us/step - loss: 1106778456.8121\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 1s 504us/step - loss: 1181612573.9100\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 1s 517us/step - loss: 1092839834.4423\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 1s 516us/step - loss: 1137382510.6301\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 1s 533us/step - loss: 1045190181.8513\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 1s 533us/step - loss: 1180922173.8239\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 1s 576us/step - loss: 1107252243.2935\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 1s 611us/step - loss: 1007642379.1292\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 475us/step - loss: 1205486386.4462\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 443us/step - loss: 1058215489.1233\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 1s 663us/step - loss: 1030302184.8904\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 1025416285.7495\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 1070991464.6419\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 1s 733us/step - loss: 1171092279.5949\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 1s 700us/step - loss: 1045908810.5656\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 1s 654us/step - loss: 962028371.7250\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 1s 617us/step - loss: 1006307508.5186\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 1s 761us/step - loss: 1089289593.7084\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 1s 690us/step - loss: 1052442955.8317\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 1s 660us/step - loss: 931867943.9726\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 1s 622us/step - loss: 1135214329.5577\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 1s 657us/step - loss: 955327253.5225\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 1s 895us/step - loss: 908197520.8141\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 1s 540us/step - loss: 1136256127.9609\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 1s 666us/step - loss: 1042534707.2544\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 1s 511us/step - loss: 901660536.5758\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 486us/step - loss: 887275778.4697\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 1s 704us/step - loss: 1065469711.4188\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 1s 918us/step - loss: 1035423578.8395\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 1s 811us/step - loss: 985836892.5871\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 1s 759us/step - loss: 1054278795.4716\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 1s 645us/step - loss: 832089390.2427\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 1s 676us/step - loss: 837922629.5773\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 1s 627us/step - loss: 848272383.2730\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 1s 548us/step - loss: 946209962.6595\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 1s 684us/step - loss: 1019115460.5714\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 1s 517us/step - loss: 911937253.7065\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 1s 510us/step - loss: 1043411631.5186\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 1s 508us/step - loss: 841568483.4305\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 1s 563us/step - loss: 829791456.7006\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 1s 569us/step - loss: 805303159.6908\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 1s 561us/step - loss: 753110992.2740\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 487us/step - loss: 838590420.4892\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 1s 491us/step - loss: 933484732.9980\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 1s 491us/step - loss: 828903559.6517\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 1s 498us/step - loss: 842467136.7397\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 489us/step - loss: 909626448.9569\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 1s 492us/step - loss: 819110945.1321\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 1s 491us/step - loss: 863649186.5127\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 1s 515us/step - loss: 825931532.2779\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 1s 514us/step - loss: 814380739.6399\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 1s 502us/step - loss: 870486174.2524\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 487us/step - loss: 808418240.5401\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 1s 526us/step - loss: 801238429.1429\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 479us/step - loss: 752560129.1468\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 1s 495us/step - loss: 715316994.6869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22be5f29d68>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=100,batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 0s 382us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test,y_test,batch_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1082658238.3652968"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= model.predict(X_test,batch_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn score:0.571325879765\n"
     ]
    }
   ],
   "source": [
    "print('nn' + \" score:\" + str(np.sqrt(np.mean((np.log(y_pred)-np.log(y_test))*(np.log(y_pred)-np.log(y_test))))))\n",
    "#print('nn' + \" score:\" + str(np.sqrt(np.mean((y_pred-y_test)*(y_pred)-y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = minmaxscaler.transform(test[cols1].values.astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(test1,batch_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_result = pd.DataFrame(data = result,columns=['SalePrice'])\n",
    "result1 = pd.concat([test['Id'],predicted_result],axis=1)\n",
    "result1.to_csv('../apartment/data_result/neural_network_17layers_batch5.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# load dataset\n",
    "dataframe = pandas.read_csv('../apartment/train.csv', delim_whitespace=True, header=None)\n",
    "dataset = dataframe.values\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:, 0:13]\n",
    "Y = dataset[:, 13]\n",
    "# define base mode\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_dim=13, init='normal', activation='relu'))\n",
    "    model.add(Dense(1, init='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimator = KerasRegressor(build_fn=baseline_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "# use 10-fold cross validation to evaluate this baseline model\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.5\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e037d009b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
